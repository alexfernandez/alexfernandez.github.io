<!DOCTYPE HTML>
<!--
	Read Only by HTML5 UP
	html5up.net | @n33co
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)

	Modified by Alex Fern√°ndez
	https://pinchito.es/ | @pinchito
-->
<html>
	<head>
		<title>node.js: ¬ør√°pido como el rayo?</title>
		<meta charset="utf-8" />
		<meta name="description" content="node.js: ¬ør√°pido como el rayo? ‚Äî " />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<meta name="twitter:card" content="summary" />
		<meta name="twitter:site" content="@pinchito" />
		<meta name="twitter:title" content="node.js: ¬ør√°pido como el
rayo? ‚Äî " />
		<meta name="twitter:description" content="" />
		<meta name="twitter:image" content="" />
		<meta property="og:title" content="node.js: ¬ør√°pido como el rayo? ‚Äî " />
		<meta property="og:type" content="website" />
		<meta property="og:description" content="" />
		<meta property="og:image" content="" />
		<meta property="og:url" content="https://pinchito.es/2013/nodejs-rapido-como-el-rayo" />
		<link rel="stylesheet" href="/css/main.css" />
		<link rel="canonical" href="https://pinchito.es/2013/nodejs-rapido-como-el-rayo" />
		<link rel="shortcut icon" href="/favicon.png" type="image/png" />
		<!--[if lte IE 8]><link rel="stylesheet" href="/css/ie8.css" /><![endif]-->
	</head>
	<body>

		<!-- Header -->
			<section id="header">
				<header>
					<p class="home"><a class="home" href="/">pinchito.es</a></p>
					<p>
					<a href="/about">about</a>
					<br/>
					<a href="/cv">CV</a>
					<br/>
					<a href="/rss.xml">
						<svg aria-hidden="true" class="rss-icon" width="18" height="18" viewBox="0 0 18 18"><path d="M3 1a2 2 0 0 0-2 2v12c0 1.1.9 2 2 2h12a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2zm0 1.5c6.9 0 12.5 5.6 12.5 12.5H13C13 9.55 8.45 5 3 5zm0 5c4.09 0 7.5 3.41 7.5 7.5H8c0-2.72-2.28-5-5-5zm0 5c1.36 0 2.5 1.14 2.5 2.5H3z"></path></svg>
						RSS feed</a>
					</p>
					<p>
					<a href="https://bsky.app/profile/pinchito.bsky.social" target="_blank">ü¶ã @pinchito.bsky.social</a>
					<br />
					<a rel="me" href="https://mastodon.social/@pinchito" target="_blank">üêò @pinchito@mastodon.social</a>
					<br/>
					<a href="https://github.com/alexfernandez" aria-label="Follow @alexfernandez on GitHub">alexfernandez @ GitHub</a>
					</p>
					<p>
					This site is cookie free! No tracking is done on your browser.
					</p>
					<a href="https://librecounter.org/referer/show" target="_blank">
					<img src="https://librecounter.org/counter.svg" referrerPolicy="unsafe-url">
					</a>
				</header>
			</section>

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Main -->
					<div id="main">

						<section id="zero">
							<p class="home"><a class="home" href="/">pinchito.es</a></p>
						</section>

						<!-- One -->
							<section id="one">
								<div class="container">
									<header class="major">
										<h1>node.js: ¬ør√°pido como el rayo?</h1>
										<p><p>
									</header>
																				<figure>
<img src="pics/nodejs-rapido-como-el-rayo.jpg"
title="Tormenta sobre Madrid (Salamanca) 01" alt="Imagen: MGR!" />
<figcaption aria-hidden="true">Imagen: <a
href="http://commons.wikimedia.org/wiki/File:Tormenta_sobre_Madrid_%28Salamanca%29_01.jpg">MGR!</a></figcaption>
</figure>
<p>Muchos de vosotros habr√©is llegado a node.js atra√≠dos por su supuesta
‚Äúvelocidad‚Äù. ¬øEs realmente tan r√°pido sirviendo p√°ginas web como lo
pintan? En esta entrada vamos a investigar un poco sobre este mito,
tomando como banco de pruebas un clon experimental de memcached hecho en
node: <a href="https://npmjs.org/package/nodecached">nodecached</a>. Por
el camino haremos unas cuantas <a href="pruebas-de-carga.html">pruebas
de carga</a> y veremos algunos trucos de optimizaci√≥n.</p>
<h2 id="comparaciones-odiosas">Comparaciones odiosas</h2>
<p>Se oye a menudo por ah√≠ que node.js es muy r√°pido. ¬øQu√© quiere decir
eso exactamente? Sabemos que node es un servidor que corre c√≥digo
JavaScript; aunque su motor V8 (adaptado de Chrome) sea muy r√°pido,
sigue siendo un lenguaje interpretado, lo que claramente es una
desventaja frente a c√≥digo nativo ‚Äî e incluso frente a c√≥digo gestionado
como Java o .NET. ¬øHasta d√≥nde llega esa desventaja?</p>
<h3 id="eligiendo-el-campo-de-batalla">Eligiendo el campo de
batalla</h3>
<p>La mejor forma de encontrar los l√≠mites del rendimiento es hacer una
comparativa con un servidor r√°pido.</p>
<p>En esta ocasi√≥n vamos a dejarnos de servidores web: en su lugar,
jugaremos con un servidor que tiene un protocolo sencillo y f√°cil de
replicar. Y no se trata del t√≠pico chat.</p>
<p>Pod√≠amos hacer como todo el mundo y comparar node.js <a
href="http://stackoverflow.com/questions/9290160/node-js-vs-net-performance">contra
.NET</a>. Al fin y al cabo ya lo ha hecho <a
href="http://www.salmanq.com/blog/net-and-node-js-performance-comparison/2013/03/">mucha</a>
<a
href="http://guillaume86.calepin.co/dotnet-vs-nodejs-performance.html">gente</a>,
¬øqu√© da√±o puede haber en un art√≠culo m√°s? Y ya puestos, ¬øpor qu√© no
contra <a
href="http://stackoverflow.com/questions/16253557/in-http-mode-does-node-js-have-substantial-performance-advantage-over-java">Java</a>?,
o para ser m√°s precisos contra Tomcat o alg√∫n otro servidor J2EE. Este
campo est√° tambi√©n <a
href="http://java.dzone.com/articles/performance-comparison-between">muy
trillado</a>. Y no hablemos del <a
href="http://zgadzaj.com/benchmarking-nodejs-basic-performance-tests-against-apache-php">pobre</a>
<a
href="http://www.appdynamics.com/blog/2013/10/17/an-example-of-how-node-js-is-faster-than-php/">PHP</a>‚Ä¶</p>
<p>No, estos servidores de uso mayoritariamente corporativo est√°n
altamente optimizados para lo que hacen, pero siguen teniendo
limitaciones b√°sicas: m√°quinas virtuales que corren c√≥digo gestionado.
Adem√°s, los servidores web a√±aden peso al procesamiento; en el mejor de
los casos estar√≠amos probando su eficiencia interna. Vamos a intentar
llegar un poco m√°s abajo en el stack, qued√°ndonos al nivel de socket.
Elegimos como contendiente a <a
href="http://memcached.org/">memcached</a>: un servidor escrito en C y
optimizado hasta la muerte por usuarios interesados (embarcados, entre
otras cosas, en pugnas de velocidad con Redis). El manejo de datos
interno es adem√°s muy sencillo: una simple cach√© LRU en memoria. ¬øQu√©
mejor rival para verificar la supuesta velocidad de node.js?</p>
<p>Para tener m√°s base de comparaci√≥n usamos tambi√©n <a
href="http://www.couchbase.com/couchbase-server/overview">Couchbase
Server</a>: una base de datos NoSQL que tiene el mismo protocolo que
memcached pero una implementaci√≥n diferente en Erlang y C.</p>
<h3 id="clonando-memcached">Clonando memcached</h3>
<p>Hacer un clon de memcached es relativamente f√°cil: el <a
href="https://github.com/memcached/memcached/blob/master/doc/protocol.txt">protocolo
b√°sico</a> es muy sencillo. La operaci√≥n <code>set key ... value</code>
recibe una clave y un valor y los guarda. Opcionalmente podemos
especificar un tiempo de vida del objeto y unos flags. Con
<code>get key</code> pasamos la clave y obtenemos el valor. Por √∫ltimo,
<code>delete key</code> borra la clave y el valor asociado.</p>
<p>Vaya por delante que no estamos innovando mucho: buscando por
‚Äúmemcached server node.js‚Äù encontramos un tipo que ha hecho un <a
href="https://groups.google.com/forum/#!topic/nodejs/gqZZmMf3W5M">clon
de memcached</a> en 100 l√≠neas (<a
href="https://gist.github.com/fxsjy/3291755">200 incluyendo la cach√©
LRU</a>). Pero es un ejercicio interesante: el caso de uso est√° bastante
cerca de un servidor corporativo que no sea web. Curiosamente, hay
muchas librer√≠as en npm <a
href="https://npmjs.org/search?q=memcached">relacionadas con
memcached</a>, muchos clientes y utilidades, pero no he encontrado
ning√∫n servidor.</p>
<p>El resultado es <a
href="https://npmjs.org/package/nodecached">nodecached</a>, una
implementaci√≥n muy b√°sica que hasta el momento ni siquiera libera
memoria cuando deber√≠a. Implementamos s√≥lo versiones simplificadas de
los comandos b√°sicos: <code>get</code>, <code>set</code> y
<code>delete</code>. El plan es completar los comandos, cosa que no
deber√≠a ser dif√≠cil ya que el <a
href="https://github.com/alexfernandez/nodecached/blob/master/lib/parser.js">parser</a>
es configurable.</p>
<p>Por ahora lo que tenemos nos servir√° para nuestros aviesos
prop√≥sitos: podemos jugar con el c√≥digo y probar diferentes par√°metros
de optimizaci√≥n.</p>
<h3 id="librer√≠a-cliente">Librer√≠a cliente</h3>
<p>Una vez implementado el servidor tenemos que escribir tambi√©n un <a
href="https://github.com/alexfernandez/nodecached/blob/master/lib/client.js">cliente</a>,
y una <a
href="https://github.com/alexfernandez/nodecached/blob/master/lib/loadtest.js">librer√≠a
de pruebas de carga</a> similar a <a href="pruebas-de-carga.html">la que
ya vimos en su momento</a>.</p>
<p>La librer√≠a funciona de la siguiente manera: lanza un n√∫mero de
peticiones GET con una clave aleatoria, que por lo tanto no van a
devolver nada. Y ya est√°: ni escritura previa, ni precalentamiento, ni
nada. Se considera que la petici√≥n ha tenido √©xito si no da error
(aunque no devuelva nada).</p>
<p>Podemos elegir el nivel de concurrencia con la opci√≥n <code>-c</code>
y el n√∫mero de peticiones con <code>-n</code>, como con <a
href="http://httpd.apache.org/docs/2.2/programs/ab.html">Apache ab</a>.
Luego s√≥lo tenemos que pasar el puerto, por ejemplo:</p>
<pre><code>$ node bin/loadtest.js -c 10 -n 100000 11211</code></pre>
<p>lanzar√° cien mil peticiones con concurrencia 10 contra un servidor en
el puerto por defecto de memcached, 11211. Si queremos probar contra el
Couchbase instalado localmente s√≥lo tenemos que cambiar el puerto al
11212:</p>
<pre><code>$ node bin/loadtest.js -c 10 -n 10000 11212</code></pre>
<p>La salida, tambi√©n inspirada en Apache ab, nos muestra los resultados
de esta forma:</p>
<pre><code>Concurrency Level:      10
Time taken for tests:   0.399 seconds
Complete requests:      10000
Failed requests:        0
Requests per second:    25063 [#/sec] (mean)
Time per request:       0.0399 [ms] (mean)
Time per request:       0.00399 [ms] (mean, across all concurrent requests)</code></pre>
<p>En este caso todas las pruebas (10000) han finalizado correctamente.
En lo sucesivo mostraremos s√≥lo las partes relevantes de la salida,
normalmente las peticiones por segundo y poco m√°s.</p>
<h2 id="las-pruebas">Las pruebas</h2>
<p>Llega el momento de arrancar nuestro invento.</p>
<h3 id="la-m√°quina">La m√°quina</h3>
<p>El ordenador elegido para las pruebas tiene un procesador i3-2120T
<span class="citation" data-cites="2.60GHz">@2.60GHz</span> con s√≥lo dos
cores, elegido por su bajo consumo y no por su rendimiento estelar ‚Äî no
en vano es un procesador de port√°til. Corre Debian testing con la
versi√≥n de node 0.8.23, un tanto anticuada; m√°s adelante probaremos
tambi√©n la 0.10.20 para comprobar si hay diferencias.</p>
<h3 id="el-servidor">El servidor</h3>
<p>Como aconsejaron al <a
href="https://groups.google.com/forum/#!topic/nodejs/gqZZmMf3W5M">clonador
de las 100 l√≠neas</a>, arrancamos el servidor con la opci√≥n
<code>--nouse_idle_notification</code> para domesticar un poco la
m√°quina virtual y que no recoja la basura cuando le parezca. Elegimos el
puerto 11311 para nuestro servidor:</p>
<pre><code>$ node --nouse_idle_notification bin/nodecached.js -p 11311</code></pre>
<p>Y ¬°ya estamos andando!</p>
<h3 id="el-cliente">El cliente</h3>
<p>Vamos a correr nuestro cliente b√°sico contra los tres servidores en
puertos diferentes:</p>
<ul>
<li>11211: memcached 1.4.13.</li>
<li>11212: CouchBase community 1.8.1.</li>
<li>11311: node.js 0.8.23.</li>
</ul>
<p>La primera prueba ir√° con concurrencia uno: un solo cliente lanzando
peticiones en serie. Los resultados son los siguientes, primero para
nuestro servidor nodecached:</p>
<pre><code>$ node bin/loadtest.js -n 10000 11311
Concurrency Level:      1
Time taken for tests:   0.877 seconds
Complete requests:      10000
Requests per second:    11403 [#/sec] (mean)
Time per request:       0.0877 [ms] (mean)</code></pre>
<p>A continuaci√≥n para memcached:</p>
<pre><code>$ node bin/loadtest.js -n 10000 11211
Concurrency Level:      1
Time taken for tests:   0.898 seconds
Complete requests:      10000
Failed requests:        0
Requests per second:    11136 [#/sec] (mean)
Time per request:       0.0898 [ms] (mean)</code></pre>
<p>Y por √∫ltimo para Couchbase:</p>
<pre><code>$ node bin/loadtest.js -n 10000 11212
Concurrency Level:      1
Time taken for tests:   0.871 seconds
Complete requests:      10000
Failed requests:        0
Requests per second:    11481 [#/sec] (mean)
Time per request:       0.0871 [ms] (mean)a</code></pre>
<p>M√°s de 11000 peticiones por segundo, que vamos a abreviar a 11
kreq/s. ¬°Qu√© bien!, ¬øno?</p>
<p>Es curioso: los tres servidores tienen una respuesta muy parecida,
cuando son tres programas completamente diferentes en lenguajes
distintos. ¬øNo ser√° una limitaci√≥n fundamental de nuestro cliente?
Primero vamos a intentar aumentar el nivel de concurrencia a 10:</p>
<pre><code>$ node bin/loadtest.js -n 10000 -c 10 --delay 11311
Concurrency Level:      10
Time taken for tests:   0.608 seconds
Complete requests:      10000
Failed requests:        0
Requests per second:    16447 [#/sec] (mean)</code></pre>
<p>A partir de este punto nos quedaremos s√≥lo con las peticiones por
segundo, tomaremos tres medidas y mostraremos la media. Los resultados
son:</p>
<pre><code>nodecached: 16.1 kreq/s,
memcached: 16 kreq/s,
Couchbase: 16.3 kreq/s.</code></pre>
<p>¬°Otra vez resultados muy parecidos! Probando con distintas
concurrencias no conseguimos mejores tiempos. Lo que necesitamos es
contrastar el rendimiento con otro cliente diferente.</p>
<h3 id="mc-benchmark">MC Benchmark</h3>
<p>Esta librer√≠a con nombre de rapero geek est√° escrita en C, y hay que
compilarla a partir del <a
href="https://github.com/antirez/mc-benchmark">c√≥digo fuente</a>. El
autor, Salvatore Sanfilippo, es un desarrollador de Redis que port√≥ la
librer√≠a de redis-benchmark para obtener comparaciones fiables.</p>
<p>La lanzamos con concurrencia 50 (el valor por defecto) y cien mil
peticiones:</p>
<pre><code>$ ./mc-benchmark -n 100000 -p 11311</code></pre>
<p>Los resultados son completamente diferentes:</p>
<pre><code>====== SET ======
  100000 requests completed in 4.07 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

[...]
24557.96 requests per second

====== GET ======
  100000 requests completed in 3.48 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

[...]
28727.38 requests per second</code></pre>
<p>(He eliminado la informaci√≥n de percentiles por brevedad.) Los
resultados son mucho mejores que antes. ¬øC√≥mo se compara ahora con los
otros servidores?</p>
<ul>
<li>nodecached: 25 kreq/s para set y casi 29 kreq/s para get.</li>
<li>memcached: 62 kreq/s para set y ¬°<em>76 kreq/s</em>! para get.
Dif√≠cil de batir.</li>
<li>Couchbase: ‚Äús√≥lo‚Äù 29 kreq/s para set y otros 29 kreq/s para get,
parecido a nuestro nodecached.</li>
</ul>
<p>A partir de este punto nuestra labor es doble: mejorar el cliente
para que d√© resultados m√°s fiables, y optimizar el servidor para que se
acerque al memcached nativo, que es la parte interesante.</p>
<h3 id="mejorando-el-cliente">Mejorando el cliente</h3>
<p>¬øPor qu√© molestarse en optimizar nuestro cliente, teniendo otro en C
que parece mucho m√°s fiable‚Ä¶ o al menos m√°s r√°pido? F√°cil: nuestra
preocupaci√≥n es mejorar el rendimiento de node.js, y eso incluye tanto
el cliente como el servidor. El cliente es, de hecho, la fruta madura
que m√°s f√°cil vamos a poder recoger.</p>
<p>La respuesta a nuestros problemas de rendimiento la encontramos en el
admirable <a
href="http://blog.caustik.com/2012/04/08/scaling-node-js-to-100k-concurrent-connections/">blog
de caustik</a> que ya hemos usado alguna que otra vez: s√≥lo tenemos que
deshabilitar el <a
href="http://en.wikipedia.org/wiki/Nagle%27s_algorithm">algoritmo de
Nagle</a> que cachea los datos en local antes de enviarlos. Con esta
sencilla mejora en el cliente, nuestro nodecached llega a rozar las 30
kreq/s, y memcached otro tanto. S√≥lo Couchbase se queda rezagada con
14~17 kreq/s.</p>
<p>Por este frente hemos alcanzado un muro: el cliente no pasa de las 30
kreq/s, lo que nos impide medir la respuesta de los servidores que
responden m√°s r√°pido.</p>
<h3 id="mejorando-el-servidor">Mejorando el servidor</h3>
<p>Ahora vamos a aplicar la misma mejora al servidor: llamar a <a
href="http://nodejs.org/api/net.html#net_socket_setnodelay_nodelay"><code>socket.setNoDelay()</code></a>
para desactivar el algoritmo de Nagle. Medimos primero la respuesta con
nuestro cliente nodecached: como nos esper√°bamos, no pasamos de 30
kreq/s. Pero con mc-benchmark la cosa se pone m√°s interesante: ¬°ahora
pasamos de los 31 kreq/s! Es una mejora interesante.</p>
<p>Llegados a este punto, tenemos que pararnos a pensar, mal que nos
pese hacer funcionar los engranajes oxidados de nuestras cabecitas. ¬øEn
qu√© se nos va el tiempo en el servidor? ¬øPodemos mejorar la respuesta de
nodecached como sea? Es posible que el procesamiento interno de los
comandos memcached sea realmente costoso; en comentarios al <a
href="https://gist.github.com/fxsjy/3244607">clon de 100 l√≠neas</a> hay
varias sugerencias de no traducir Buffer a String. As√≠ que montamos una
nueva opci√≥n de nodecached <code>--error</code> que elimina
completamente el procesamiento interno: siempre devuelve ERROR a
cualquier consulta. ¬øQu√© tal responder√° a las pruebas?</p>
<p>El cliente nodecached responde, como era de esperar, alrededor de 30
kreq/s. Es en mc-benchmark donde se nota realmente la mejora:</p>
<pre><code>$ ./mc-benchmark -n 100000 -p 11311
====== SET ======
  100000 requests completed in 1.94 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

51546.39 requests per second

====== GET ======
  100000 requests completed in 2.00 seconds
  50 parallel clients
  3 bytes payload
  keep alive: 1

50050.05 requests per second</code></pre>
<p>¬°M√°s de 50 kreq/s! En varias pruebas reales los resultados oscilan
entre 46 y 53 kreq/s. Es un resultado fabuloso, a un 70% de la
eficiencia de C, aunque realmente no estamos haciendo nada.</p>
<p>Por poner los resultados en perspectiva, 50 kreq/s quiere decir que
estamos usando alrededor de 20 ¬µs (20 microsegundos, o sea 20
millon√©simas de segundo) por consulta. Por su parte, el memcached
original usa unos 14 ¬µs.</p>
<p>En lo que respecta al servidor hemos alcanzado el l√≠mite de nuevo:
ahora ya pr√°cticamente s√≥lo nos queda el c√≥digo de entrada/salida de
node.js, que est√° fuera del alcance de nuestras manazas. Pero sin llegar
al extremo de perder toda la funcionalidad, volvamos al servidor
completo que nos daba unos 30 kreq/s. ¬øPodemos mejorar el tiempo de
proceso interno usando <code>Buffer</code>s en lugar de convertir a
<code>String</code>? Es una opci√≥n interesante, pero es cuestionable si
la posible mejora merece la pena: sabemos que no vamos a pasar de 50
kreq/s en ning√∫n caso. La mayor parte del tiempo en una consulta
memcached se va en la red, as√≠ que optimizar 10 ¬µs no es una prioridad
ahora mismo.</p>
<h3 id="otras-pruebas">Otras pruebas</h3>
<p>La diversi√≥n no termina aqu√≠: podemos hacer m√°s pruebas a ver si
mejoramos el cliente. Por ejemplo, podemos usar el <a
href="https://github.com/3rd-Eden/node-memcached">cliente memcached</a>
m√°s popular a ver si mejora la cosa. A√±adimos una opci√≥n
<code>--memcached</code> a loadtest para probarlo. Los resultados son
decepcionantes.</p>
<pre><code>$ node bin/loadtest.js -c 10 -n 100000 --memcached 11311
Concurrency Level:      10
Time taken for tests:   7.897 seconds
Complete requests:      100000
Failed requests:        0
Requests per second:    12663 [#/sec] (mean)</code></pre>
<p>Menos de 13 kreq/s, o sea menos de la mitad que nuestro cliente
optimizado. Una prueba con node v0.10.x tampoco da los resultados
esperados:</p>
<pre><code>$ ~/install/node-v0.10.20/out/Release/node bin/loadtest.js -c 10 -n 100000 11311
Concurrency Level:      10
Time taken for tests:   4.569 seconds
Complete requests:      100000
Failed requests:        0
Requests per second:    21887 [#/sec] (mean)</code></pre>
<p>No llega ni a los resultados de node v0.8.x.</p>
<p>Ahora llega la parte m√°s bizarra de toda esta historia. Otra posible
optimizaci√≥n del cliente que nos hemos dejado por el camino es aplicar
la t√©cnica de ignorar los mensajes que nos llegan, como hemos hecho en
el servidor. En el cliente es mucho m√°s f√°cil: lanzamos un
<code>get</code> y no tenemos que esperar a la respuesta porque ya
sabemos que el elemento buscado no existe. As√≠ que a√±adimos una opci√≥n
<code>--noreply</code> a loadtest.js que hace justamente eso. ¬øC√≥mo
queda el rendimiento con la nueva opci√≥n?</p>
<pre><code>$ node bin/loadtest.js -c 10 -n 100000 --noreply 11311
Concurrency Level:      10
Time taken for tests:   6.009 seconds
Complete requests:      100000
Failed requests:        0
Requests per second:    16642 [#/sec] (mean)</code></pre>
<p>Sorpresa, sorpresa: ¬°mucho peor que antes! No llegamos ni a los 20
kreq/s. ¬øPor qu√©? Aqu√≠ tengo que confesar humildemente que no tengo ni
idea. He probado un mont√≥n de cosas, sin √©xito: ignorar las respuestas
del servidor empeora sensiblemente el rendimiento.</p>
<p>Por favor, si tienes una idea de qu√© est√° pasando, ponla en los
comentarios.</p>
<h2 id="revisando-el-mito">Revisando el mito</h2>
<p>El rendimiento bruto de node.js para c√°lculos intensivos es <a
href="http://engineering.linkedin.com/nodejs/blazing-fast-nodejs-10-performance-tips-linkedin-mobile">notoriamente
malo</a>. Para c√°lculos puros y duros los lenguajes compilados lo tienen
mucho m√°s f√°cil, ya que el c√≥digo generado est√° optimizado directamente
para su ejecuci√≥n. Incluso dentro de lenguajes interpretados, los que
tienen tipado fuerte, o incluso s√≥lo con tipado d√©bil, tienen una
ventaja intr√≠nseca: el int√©rprete (o modernamente la m√°quina virtual)
sabe qu√© espacio reservar para cada variable y no tiene que jugar con la
memoria.</p>
<p>Entonces, ¬øes m√°s r√°pida la entrada/salida que en otros lenguajes? En
el caso de C o C++ est√° claro que un programa bien escrito, aprovechando
la meticulosa gesti√≥n de cada byte, ser√° probablemente m√°s r√°pido. A no
ser que uses los sucios trucos de <a
href="https://www.youtube.com/watch?v=Kdwwvps4J9A">Felix
Geisend√∂rfer</a>, cosa que siempre hay que considerar. Pero nadie
recomienda servir recursos est√°ticos con node.js. ¬øEntonces?</p>
<h3 id="carga-y-velocidad">Carga y velocidad</h3>
<p>Lo que probablemente quieren decir los bien-intencionados
evangelistas que cantan las virtudes de node.js es que aguanta mucha
carga. Esto es bastante diferente: en lugar de fijarnos en la velocidad,
lo que nos importa es el volumen de peticiones que vamos a soportar.</p>
<p>Lo maravilloso de node.js es realmente su respuesta tan lineal: el
doble de peticiones por segundo resulta en el doble de carga. Esta
predecibilidad es m√°s valiosa muchas veces que un rendimiento incre√≠ble
de media pero desbocado en ocasiones.</p>
<h2 id="conclusi√≥n">Conclusi√≥n</h2>
<p>En este viaje conjunto hemos pasado de un servidor sin optimizar a
otro que se acerca a la eficiencia de C, perdiendo toda la funcionalidad
por el camino. Las lecciones que podemos destacar son:</p>
<ul>
<li>La experiencia de primera mano no tiene sustituto: desconf√≠a de las
verdades populares que se encuentran por ah√≠.</li>
<li>Optimiza para tu caso concreto. Por m√°s benchmarks que leas en
internet, no hay nada mejor que probar contra tus circunstancias.</li>
<li>D√©jalo a tiempo. Es f√°cil alcanzar el punto de retornos decrecientes
sin darse cuenta y seguir en una carrera sin sentido.</li>
</ul>
<p>Espero haberte animado a probar alguna cosa nueva. Si tienes dudas,
sugerencias o cr√≠ticas acerbas, deja tu comentario debajo.</p>
								</div>
							</section>
							<section id="last">
								<div class="container">
									<p>
									Original publicado en <a
href="http://www.godtic.com/blog/2013/11/12/node-js-rapido-como-el-rayo/">GodTIC</a>
el 2013-11-12.
									</p>
									<p>
									Back to the <a href="/">index</a>.
									</p>
								</div>
							</section>

				<!-- Footer -->
					<section id="footer">
						<div class="container">
							<ul class="copyright">
								<li>
									¬© <a href="mailto:alexfernandeznpm@gmail.com">Alex Fern√°ndez</a>.
									<a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a>.
								</li>
								<li>Original design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</div>
					</section>

			</div>
	</body>
</html>
